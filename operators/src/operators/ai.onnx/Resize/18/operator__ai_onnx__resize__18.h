//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__RESIZE__18_H
# define OPERATOR_OPERATOR__AI_ONNX__RESIZE__18_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'Resize' version 18
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.
 * Each dimension value of the output tensor is: <br/>
 *   `output_dimension = floor(input_dimension * (roi_end - roi_start) * scale)` <br/>
 * if input \"sizes\" is not specified.
 * 
 * Constraint T1:
 *   Constrain input 'X' and output 'Y' to all tensor types.
 *   Allowed Types: tensor_bfloat16, tensor_bool, tensor_complex128,
 *                  tensor_complex64, tensor_double, tensor_float,
 *                  tensor_float16, tensor_int16, tensor_int32, tensor_int64,
 *                  tensor_int8, tensor_string, tensor_uint16, tensor_uint32,
 *                  tensor_uint64, tensor_uint8
 * 
 * Constraint T2:
 *   Constrain roi type to float or double.
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * Input T1 X:
 *   N-D tensor
 *   Allowed Types: tensor_bfloat16, tensor_bool, tensor_complex128,
 *                  tensor_complex64, tensor_double, tensor_float,
 *                  tensor_float16, tensor_int16, tensor_int32, tensor_int64,
 *                  tensor_int8, tensor_string, tensor_uint16, tensor_uint32,
 *                  tensor_uint64, tensor_uint8
 * 
 * Input T2 roi:
 *   1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is
 *   the rank of X or the length of axes, if provided. The RoIs' coordinates
 *   are normalized in the coordinate system of the input image. It only takes
 *   effect when coordinate_transformation_mode is "tf_crop_and_resize"
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * 
 * Input tensor(float) scales:
 *   The scale array along each dimension. It takes value greater than 0. If
 *   it's less than 1, it's sampling down, otherwise, it's upsampling. The
 *   number of elements of 'scales' should be the same as the rank of input 'X'
 *   or the length of 'axes', if provided. One of 'scales' and 'sizes' MUST be
 *   specified and it is an error if both are specified. If 'sizes' is needed,
 *   the user can use an empty string as the name of 'scales' in this
 *   operator's input list.
 *   Allowed Types: tensor_float
 * 
 * Input tensor(int64) sizes:
 *   Target size of the output tensor. Its interpretation depends on the
 *   'keep_aspect_ratio_policy' value.The number of elements of 'sizes' should
 *   be the same as the rank of input 'X', or the length of 'axes', if
 *   provided. Only one of 'scales' and 'sizes' can be specified.
 *   Allowed Types: tensor_int64
 * Output T1 Y:
 *   N-D tensor after resizing
 *   Allowed Types: tensor_bfloat16, tensor_bool, tensor_complex128,
 *                  tensor_complex64, tensor_double, tensor_float,
 *                  tensor_float16, tensor_int16, tensor_int32, tensor_int64,
 *                  tensor_int8, tensor_string, tensor_uint16, tensor_uint32,
 *                  tensor_uint64, tensor_uint8
 * Attribute INT antialias (optional):
 *   If set to 1, "linear" and "cubic" interpolation modes will use an
 *   antialiasing filter when downscaling. Antialiasing is achieved by
 *   stretching the resampling filter by a factor max(1, 1 / scale), which
 *   means that when downsampling, more input pixels contribute to an output
 *   pixel.
 * 
 * Attribute INTS axes (optional):
 *   If provided, it specifies a subset of axes that 'roi', 'scales' and
 *   'sizes' refer to. If not provided, all axes are assumed [0, 1, ..., r-1],
 *   where r = rank(data). Non-specified dimensions are interpreted as
 *   non-resizable. Negative value means counting dimensions from the back.
 *   Accepted range is [-r, r-1], where r = rank(data). Behavior is undefined
 *   if an axis is repeated.
 * 
 * Attribute STRING coordinate_transformation_mode (optional):
 *   This attribute describes how to transform the coordinate in the resized
 *   tensor to the coordinate in the original tensor. <br/> The coordinate of
 *   each dimension is transformed individually. Let's describe a case using
 *   axis x as an example. Denote x_resized as the coordinate of axis x in the
 *   resized tensor, x_original as the coordinate of axis x in the original
 *   tensor, `length_original` as the length of the original tensor in axis x,
 *   length_resized as the length of the resized tensor in axis x, roi_x =
 *   (start_x, end_x) of the axis x in input "roi", `scale = length_resized /
 *   length_original`, <br/> if coordinate_transformation_mode is
 *   `"half_pixel"`, <br/> `x_original = (x_resized + 0.5) / scale - 0.5` <br/>
 *   if coordinate_transformation_mode is `"pytorch_half_pixel"`, <br/>
 *   `x_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0`
 *   <br/> if coordinate_transformation_mode is `"align_corners"`, <br/>
 *   `x_original = x_resized * (length_original - 1) / (length_resized - 1)`
 *   <br/> if coordinate_transformation_mode is `"asymmetric"`, <br/>
 *   `x_original = x_resized / scale` <br/> if coordinate_transformation_mode
 *   is `"tf_crop_and_resize"`, <br/> `x_original = length_resized > 1 ?
 *   start_x * (length_original - 1) + x_resized * (end_x - start_x) *
 *   (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) *
 *   (length_original - 1)` .
 * 
 * Attribute FLOAT cubic_coeff_a (optional):
 *   The coefficient 'a' used in cubic interpolation. Two common choice are
 *   -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out
 *   Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the
 *   details. This attribute is valid only if mode is "cubic".
 * 
 * Attribute INT exclude_outside (optional):
 *   If set to 1, the weight of sampling locations outside the tensor will be
 *   set to 0 and the weight will be renormalized so that their sum is 1.0. The
 *   default value is 0.
 * 
 * Attribute FLOAT extrapolation_value (optional):
 *   When coordinate_transformation_mode is "tf_crop_and_resize" and
 *   x_original is outside the range [0, length_original - 1], this value is
 *   used as the corresponding output value. Default is 0.0f.
 * 
 * Attribute STRING keep_aspect_ratio_policy (optional):
 *   This attribute describes how to interpret the `sizes` input with regard
 *   to keeping the original aspect ratio of the input, and it is not
 *   applicable when the `scales` input is used. <br/> Given a set of `sizes`,
 *   associated with a subset of `axes` (explicitly provided or default), and
 *   assuming `d = axes[i]`, with `i` being the index of the provided `sizes`.
 *   <br/> If `keep_aspect_ratio_policy` is `"stretch"`, the original aspect
 *   ratio is disregarded, and the input is resized to the specified size:
 *   <br/> `out_size[d] = sizes[i]` <br/> If `keep_aspect_ratio_policy` is
 *   `"not_larger"`, the sizes are adjusted so that no extent of the output is
 *   larger than the specified size, while keeping the original aspect ratio:
 *   <br/> `scale = Min(sizes[i] / in_size[d])` <br/> `out_size[d] =
 *   round_int(scale * in_size[i])` <br/> If `keep_aspect_ratio_policy` is
 *   `"not_smaller"`, the sizes are adjusted so that no extent of the output is
 *   smaller than the specified size, while keeping the original aspect ratio:
 *   <br/> `scale = Max(sizes[i] / in_size[d])` <br/> `out_size[d] =
 *   round_int(scale * in_size[i])` <br/> For non-resizable axes (those not
 *   specified in `axes`), the output size will be equal to the input size.
 *   Note: `round_int` stands for computing the nearest integer value, rounding
 *   halfway cases up.
 * 
 * Attribute STRING mode (optional):
 *   Three interpolation modes: "nearest" (default), "linear" and "cubic". The
 *   "linear" mode includes linear interpolation for 1D tensor and N-linear
 *   interpolation for N-D tensor (for example, bilinear interpolation for 2D
 *   tensor). The "cubic" mode includes cubic interpolation for 1D tensor and
 *   N-cubic interpolation for N-D tensor (for example, bicubic interpolation
 *   for 2D tensor).
 * 
 * Attribute STRING nearest_mode (optional):
 *   Four modes: "round_prefer_floor" (default, as known as round half down),
 *   "round_prefer_ceil" (as known as round half up), "floor", "ceil". Only
 *   used by nearest interpolation. It indicates how to get "nearest" pixel in
 *   input tensor from x_original, so this attribute is valid only if "mode" is
 *   "nearest".
 *
 * @since version 18
 *
 * @see github/workspace/onnx/defs/tensor/old.cc:3202
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#Resize
 */

operator_status
prepare_operator__ai_onnx__resize__18(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__resize__18;

typedef struct {
// no attributes
} context_operator__ai_onnx__resize__18;

operator_executer
resolve_operator__ai_onnx__resize__18(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_bfloat16__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_bfloat16__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_bfloat16__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_bool__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_bool__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_bool__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_complex128__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_complex128__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_complex128__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_complex64__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_complex64__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_complex64__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_double__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_double__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_double__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_float__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_float__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_float__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_float16__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_float16__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_float16__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_int16__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_int16__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_int16__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_int32__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_int32__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_int32__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_int64__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_int64__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_int64__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_int8__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_int8__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_int8__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_string__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_string__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_string__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_uint16__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_uint16__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_uint16__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_uint32__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_uint32__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_uint32__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_uint64__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_uint64__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_uint64__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_uint8__T2_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_uint8__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__resize__18__T1_tensor_uint8__T2_tensor_float16(
    node_context *ctx
);

# endif