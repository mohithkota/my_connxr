//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__QLINEARCONV__10_H
# define OPERATOR_OPERATOR__AI_ONNX__QLINEARCONV__10_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'QLinearConv' version 10
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * The convolution operator consumes a quantized input tensor, its scale and zero point,
 * a quantized filter, its scale and zero point, and output's scale and zero point,
 * and computes the quantized output. Each scale and zero-point pair must have same shape.
 * It means they must be either scalars (per tensor) or 1-D tensors (per output channel).
 * Each input or output and its related zero point must have same type.
 * When bias is present it must be quantized using scale = input scale * weight scale and
 * zero point as 0.
 * 
 * Constraint T1:
 *   Constrain input type to 8-bit integer tensor.
 *   Allowed Types: tensor_int8, tensor_uint8
 * 
 * Constraint T2:
 *   Constrain filter type to 8-bit integer tensor.
 *   Allowed Types: tensor_int8, tensor_uint8
 * 
 * Constraint T3:
 *   Constrain output type to 8-bit integer tensor.
 *   Allowed Types: tensor_int8, tensor_uint8
 * 
 * Constraint T4:
 *   Constrain bias type to 32-bit integer tensor.
 *   Allowed Types: tensor_int32
 * Input T1 x:
 *   Input data tensor from previous layer; has size (N x C x H x W), where N
 *   is the batch size, C is the number of channels, and H and W are the height
 *   and width. Note that this is for the 2D image. Otherwise the size is (N x
 *   C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect,
 *   the operation expects input data tensor to arrive with the dimension
 *   denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
 *   Allowed Types: tensor_int8, tensor_uint8
 * 
 * Input tensor(float) x_scale:
 *   Scale tensor for input 'x'. It's a scalar, which means a per-tensor/layer
 *   quantization.
 *   Allowed Types: tensor_float
 * 
 * Input T1 x_zero_point:
 *   Zero point tensor for input 'x'. It's a scalar, which means a
 *   per-tensor/layer quantization.
 *   Allowed Types: tensor_int8, tensor_uint8
 * 
 * Input T2 w:
 *   The weight tensor that will be used in the convolutions; has size (M x
 *   C/group x kH x kW), where C is the number of channels, and kH and kW are
 *   the height and width of the kernel, and M is the number of feature maps.
 *   For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x
 *   k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel.
 *   Optionally, if dimension denotation is in effect, the operation expects
 *   the weight tensor to arrive with the dimension denotation of
 *   [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL
 *   ...]. X.shape[1] == (W.shape[1] * group) == C (assuming zero based indices
 *   for the shape array). Or in other words FILTER_IN_CHANNEL should be equal
 *   to DATA_CHANNEL.
 *   Allowed Types: tensor_int8, tensor_uint8
 * 
 * Input tensor(float) w_scale:
 *   Scale tensor for input 'w'. It could be a scalar or a 1-D tensor, which
 *   means a per-tensor/layer or per output channel quantization. If it's a 1-D
 *   tensor, its number of elements should be equal to the number of output
 *   channels (M).
 *   Allowed Types: tensor_float
 * 
 * Input T2 w_zero_point:
 *   Zero point tensor for input 'w'. It could be a scalar or a 1-D tensor,
 *   which means a per-tensor/layer or per output channel quantization. If it's
 *   a 1-D tensor, its number of elements should be equal to the number of
 *   output channels (M).
 *   Allowed Types: tensor_int8, tensor_uint8
 * 
 * Input tensor(float) y_scale:
 *   Scale tensor for output 'y'. It's a scalar, which means a
 *   per-tensor/layer quantization.
 *   Allowed Types: tensor_float
 * 
 * Input T3 y_zero_point:
 *   Zero point tensor for output 'y'. It's a scalar, which means a
 *   per-tensor/layer quantization.
 *   Allowed Types: tensor_int8, tensor_uint8
 * 
 * Input T4 B:
 *   Optional 1D bias to be added to the convolution, has size of M. Bias must
 *   be quantized using scale = x_scale * w_scale and zero_point = 0
 *   Allowed Types: tensor_int32
 * Output T3 y:
 *   Output data tensor that contains the result of the convolution. The
 *   output dimensions are functions of the kernel size, stride size, and pad
 *   lengths.
 *   Allowed Types: tensor_int8, tensor_uint8
 * Attribute STRING auto_pad (optional):
 *   auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where
 *   default value is NOTSET, which means explicit padding is used. SAME_UPPER
 *   or SAME_LOWER mean pad the input so that `output_shape[i] =
 *   ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split
 *   between the two sides equally or almost equally (depending on whether it
 *   is even or odd). In case the padding is an odd number, the extra padding
 *   is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.
 * 
 * Attribute INTS dilations (optional):
 *   dilation value along each spatial axis of the filter. If not present, the
 *   dilation defaults to 1 along each spatial axis.
 * 
 * Attribute INT group (optional):
 *   number of groups input channels and output channels are divided into.
 *   default is 1.
 * 
 * Attribute INTS kernel_shape (optional):
 *   The shape of the convolution kernel. If not present, should be inferred
 *   from input 'w'.
 * 
 * Attribute INTS pads (optional):
 *   Padding for the beginning and ending along each spatial axis, it can take
 *   any value greater than or equal to 0.The value represent the number of
 *   pixels added to the beginning and end part of the corresponding
 *   axis.`pads` format should be as follow [x1_begin, x2_begin...x1_end,
 *   x2_end,...], where xi_begin the number ofpixels added at the beginning of
 *   axis `i` and xi_end, the number of pixels added at the end of axis
 *   `i`.This attribute cannot be used simultaneously with auto_pad attribute.
 *   If not present, the padding defaultsto 0 along start and end of each
 *   spatial axis.
 * 
 * Attribute INTS strides (optional):
 *   Stride along each spatial axis. If not present, the stride defaults to 1
 *   along each spatial axis.
 *
 * @since version 10
 *
 * @see github/workspace/onnx/defs/nn/defs.cc:845
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#QLinearConv
 */

operator_status
prepare_operator__ai_onnx__qlinearconv__10(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__qlinearconv__10;

typedef struct {
// no attributes
} context_operator__ai_onnx__qlinearconv__10;

operator_executer
resolve_operator__ai_onnx__qlinearconv__10(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__qlinearconv__10(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__qlinearconv__10__T1_tensor_int8__T2_tensor_int8__T3_tensor_int8__T4_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__qlinearconv__10__T1_tensor_int8__T2_tensor_int8__T3_tensor_uint8__T4_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__qlinearconv__10__T1_tensor_int8__T2_tensor_uint8__T3_tensor_int8__T4_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__qlinearconv__10__T1_tensor_int8__T2_tensor_uint8__T3_tensor_uint8__T4_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__qlinearconv__10__T1_tensor_uint8__T2_tensor_int8__T3_tensor_int8__T4_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__qlinearconv__10__T1_tensor_uint8__T2_tensor_int8__T3_tensor_uint8__T4_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__qlinearconv__10__T1_tensor_uint8__T2_tensor_uint8__T3_tensor_int8__T4_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__qlinearconv__10__T1_tensor_uint8__T2_tensor_uint8__T3_tensor_uint8__T4_tensor_int32(
    node_context *ctx
);

# endif