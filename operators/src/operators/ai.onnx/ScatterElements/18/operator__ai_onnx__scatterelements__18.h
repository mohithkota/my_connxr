//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__SCATTERELEMENTS__18_H
# define OPERATOR_OPERATOR__AI_ONNX__SCATTERELEMENTS__18_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'ScatterElements' version 18
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * ScatterElements takes three inputs `data`, `updates`, and `indices` of the same
 * rank r >= 1 and an optional attribute axis that identifies an axis of `data`
 * (by default, the outer-most axis, that is axis 0). The output of the operation
 * is produced by creating a copy of the input `data`, and then updating its value
 * to values specified by `updates` at specific index positions specified by
 * `indices`. Its output shape is the same as the shape of `data`.
 * 
 * For each entry in `updates`, the target index in `data` is obtained by combining
 * the corresponding entry in `indices` with the index of the entry itself: the
 * index-value for dimension = axis is obtained from the value of the corresponding
 * entry in `indices` and the index-value for dimension != axis is obtained from the
 * index of the entry itself.
 * 
 * `reduction` allows specification of an optional reduction operation, which is applied to all values in `updates`
 * tensor into `output` at the specified `indices`.
 * In cases where `reduction` is set to "none", indices should not have duplicate entries: that is, if idx1 != idx2,
 * then indices[idx1] != indices[idx2]. For instance, in a 2-D tensor case, the update
 * corresponding to the [i][j] entry is performed as below:
 * ```
 * output[indices[i][j]][j] = updates[i][j] if axis = 0,
 * output[i][indices[i][j]] = updates[i][j] if axis = 1,
 * ```
 * When `reduction` is set to some reduction function `f`, the update corresponding to the [i][j] entry is performed as below:
 * ```
 * output[indices[i][j]][j] = f(output[indices[i][j]][j], updates[i][j]) if axis = 0,
 * output[i][indices[i][j]] = f(output[i][indices[i][j]], updates[i][j]) if axis = 1,
 * ```
 * where the `f` is `+`, `*`, `max` or `min` as specified.
 * 
 * This operator is the inverse of GatherElements. It is similar to Torch's Scatter operation.
 * 
 * (Opset 18 change): Adds max/min to the set of allowed reduction ops.
 * 
 * Example 1:
 * ```
 * data = [
 *     [0.0, 0.0, 0.0],
 *     [0.0, 0.0, 0.0],
 *     [0.0, 0.0, 0.0],
 * ]
 * indices = [
 *     [1, 0, 2],
 *     [0, 2, 1],
 * ]
 * updates = [
 *     [1.0, 1.1, 1.2],
 *     [2.0, 2.1, 2.2],
 * ]
 * output = [
 *     [2.0, 1.1, 0.0]
 *     [1.0, 0.0, 2.2]
 *     [0.0, 2.1, 1.2]
 * ]
 * ```
 * Example 2:
 * ```
 * data = [[1.0, 2.0, 3.0, 4.0, 5.0]]
 * indices = [[1, 3]]
 * updates = [[1.1, 2.1]]
 * axis = 1
 * output = [[1.0, 1.1, 3.0, 2.1, 5.0]]
 * ```
 * 
 * Constraint T:
 *   Input and output types can be of any tensor type.
 *   Allowed Types: tensor_bfloat16, tensor_bool, tensor_complex128,
 *                  tensor_complex64, tensor_double, tensor_float,
 *                  tensor_float16, tensor_int16, tensor_int32, tensor_int64,
 *                  tensor_int8, tensor_string, tensor_uint16, tensor_uint32,
 *                  tensor_uint64, tensor_uint8
 * 
 * Constraint Tind:
 *   Constrain indices to integer types
 *   Allowed Types: tensor_int32, tensor_int64
 * Input T data:
 *   Tensor of rank r >= 1.
 *   Allowed Types: tensor_bfloat16, tensor_bool, tensor_complex128,
 *                  tensor_complex64, tensor_double, tensor_float,
 *                  tensor_float16, tensor_int16, tensor_int32, tensor_int64,
 *                  tensor_int8, tensor_string, tensor_uint16, tensor_uint32,
 *                  tensor_uint64, tensor_uint8
 * 
 * Input Tind indices:
 *   Tensor of int32/int64 indices, of r >= 1 (same rank as input). All index
 *   values are expected to be within bounds [-s, s-1] along axis of size s. It
 *   is an error if any of the index values are out of bounds.
 *   Allowed Types: tensor_int32, tensor_int64
 * 
 * Input T updates:
 *   Tensor of rank r >=1 (same rank and shape as indices)
 *   Allowed Types: tensor_bfloat16, tensor_bool, tensor_complex128,
 *                  tensor_complex64, tensor_double, tensor_float,
 *                  tensor_float16, tensor_int16, tensor_int32, tensor_int64,
 *                  tensor_int8, tensor_string, tensor_uint16, tensor_uint32,
 *                  tensor_uint64, tensor_uint8
 * Output T output:
 *   Tensor of rank r >= 1 (same rank as input).
 *   Allowed Types: tensor_bfloat16, tensor_bool, tensor_complex128,
 *                  tensor_complex64, tensor_double, tensor_float,
 *                  tensor_float16, tensor_int16, tensor_int32, tensor_int64,
 *                  tensor_int8, tensor_string, tensor_uint16, tensor_uint32,
 *                  tensor_uint64, tensor_uint8
 * Attribute INT axis (optional):
 *   Which axis to scatter on. Negative value means counting dimensions from
 *   the back. Accepted range is [-r, r-1] where r = rank(data).
 * 
 * Attribute STRING reduction (optional):
 *   Type of reduction to apply: none (default), add, mul, max, min. 'none':
 *   no reduction applied. 'add': reduction using the addition operation.
 *   'mul': reduction using the multiplication operation.'max': reduction using
 *   the maximum operation.'min': reduction using the minimum operation.
 *
 * @since version 18
 *
 * @see github/workspace/onnx/defs/tensor/defs.cc:1432
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#ScatterElements
 */

operator_status
prepare_operator__ai_onnx__scatterelements__18(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__scatterelements__18;

typedef struct {
// no attributes
} context_operator__ai_onnx__scatterelements__18;

operator_executer
resolve_operator__ai_onnx__scatterelements__18(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_bfloat16__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_bfloat16__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_bool__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_bool__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_complex128__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_complex128__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_complex64__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_complex64__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_double__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_double__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_float__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_float__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_float16__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_float16__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_int16__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_int16__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_int32__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_int32__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_int64__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_int64__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_int8__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_int8__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_string__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_string__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_uint16__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_uint16__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_uint32__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_uint32__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_uint64__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_uint64__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_uint8__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatterelements__18__T_tensor_uint8__Tind_tensor_int64(
    node_context *ctx
);

# endif