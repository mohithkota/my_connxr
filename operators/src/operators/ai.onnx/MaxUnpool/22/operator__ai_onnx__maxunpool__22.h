//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__MAXUNPOOL__22_H
# define OPERATOR_OPERATOR__AI_ONNX__MAXUNPOOL__22_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'MaxUnpool' version 22
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * MaxUnpool essentially computes the partial inverse of the MaxPool op.
 *  The input information to this op is typically the output information from a MaxPool op. The first
 *  input tensor X is the tensor that needs to be unpooled, which is typically the pooled tensor (first output)
 *  from MaxPool. The second input tensor, I, contains the indices to the (locally maximal) elements corresponding
 *  to the elements in the first input tensor X. Input tensor I is typically the second output of the MaxPool op.
 *  The third (optional) input is a tensor that specifies the output size of the unpooling operation.
 * 
 * MaxUnpool is intended to do 'partial' inverse of the MaxPool op. 'Partial' because all the non-maximal
 *  values from the original input to MaxPool are set to zero in the output of the MaxUnpool op. Pooling
 *  the result of an unpooling operation should give back the original input to the unpooling op.
 * 
 * MaxUnpool can produce the same output size for several input sizes, which makes unpooling op ambiguous.
 *  The third input argument, output_size, is meant to disambiguate the op and produce output tensor of
 *  known/predictable size.
 * 
 * In addition to the inputs, MaxUnpool takes three attributes, namely kernel_shape, strides, and pads,
 *  which define the exact unpooling op. The attributes typically have the same values as the corresponding
 *  pooling op that the unpooling op is trying to invert.
 * 
 * Constraint T1:
 *   Constrain input and output types to float tensors.
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16
 * 
 * Constraint T2:
 *   Constrain index tensor to int64
 *   Allowed Types: tensor_int64
 * Input T1 X:
 *   Input data tensor that has to be unpooled. This tensor is typically the
 *   first output of the MaxPool op.Dimensions for image case are (N x C x H x
 *   W), where N is the batch size, C is the number of channels, and H and W
 *   are the height and the width of the data. For non-image case, the
 *   dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the
 *   batch size. Optionally, if dimension denotation is in effect, the
 *   operation expects the input data tensor to arrive with the dimension
 *   denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16
 * 
 * Input T2 I:
 *   Input data tensor containing the indices corresponding to elements in the
 *   first input tensor X.This tensor is typically the second output of the
 *   MaxPool op.Dimensions must be the same as input tensor X. The indices are
 *   linear, i.e. computed considering the tensor as flattened 1-D tensor,
 *   assuming row-major storage. Also, the linear indices should not consider
 *   padding. So the values in indices are in the range [0, N x C x D1 x ... x
 *   Dn).
 *   Allowed Types: tensor_int64
 * 
 * Input T2 output_shape:
 *   The shape of the output can be explicitly set which will cause pads
 *   values to be auto generated. If 'output_shape' is specified, 'pads' values
 *   are ignored.
 *   Allowed Types: tensor_int64
 * Output T1 output:
 *   Output data tensor that contains the result of the unpooling.
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16
 * Attribute INTS kernel_shape :
 *   The size of the kernel along each axis.
 * 
 * Attribute INTS pads (optional):
 *   Padding for the beginning and ending along each spatial axis, it can take
 *   any value greater than or equal to 0. The value represent the number of
 *   pixels added to the beginning and end part of the corresponding axis.
 *   `pads` format should be as follow [x1_begin, x2_begin...x1_end,
 *   x2_end,...], where xi_begin the number of pixels added at the beginning of
 *   axis `i` and xi_end, the number of pixels added at the end of axis `i`.
 *   This attribute cannot be used simultaneously with auto_pad attribute. If
 *   not present, the padding defaults to 0 along start and end of each spatial
 *   axis.
 * 
 * Attribute INTS strides (optional):
 *   Stride along each spatial axis. If not present, the stride defaults to 1
 *   along each spatial axis.
 *
 * @since version 22
 *
 * @see github/workspace/onnx/defs/nn/defs.cc:481
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#MaxUnpool
 */

operator_status
prepare_operator__ai_onnx__maxunpool__22(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__maxunpool__22;

typedef struct {
// no attributes
} context_operator__ai_onnx__maxunpool__22;

operator_executer
resolve_operator__ai_onnx__maxunpool__22(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__maxunpool__22(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__maxunpool__22__T1_tensor_bfloat16__T2_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__maxunpool__22__T1_tensor_double__T2_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__maxunpool__22__T1_tensor_float__T2_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__maxunpool__22__T1_tensor_float16__T2_tensor_int64(
    node_context *ctx
);

# endif