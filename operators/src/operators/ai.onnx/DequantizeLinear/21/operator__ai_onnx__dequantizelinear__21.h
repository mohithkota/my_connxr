//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__DEQUANTIZELINEAR__21_H
# define OPERATOR_OPERATOR__AI_ONNX__DEQUANTIZELINEAR__21_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'DequantizeLinear' version 21
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * The linear dequantization operator. It consumes a quantized tensor, a scale, and a zero point to compute the
 * full-precision tensor. The dequantization formula is `y = (x - x_zero_point) * x_scale`. `x_scale` and `x_zero_point`
 * must have the same shape, determining the quantization's granularity: a scalar for per-tensor/per-layer quantization,
 * a 1-D tensor for per-axis quantization, or have a rank identical to the input for blocked quantization.
 * See QuantizeLinear for details on quantization granularity.
 * 
 * `x_zero_point` and `x` must have the same type. `x` and `y` must have the same shape. In the case of dequantizing
 * `int32`, there's no zero point (zero point is supposed to be 0).
 * `zero-point` is usually not used in the case of float8 types quantization, but the dequantization formula remains the same
 * for consistency, and `x_scale` still determines the output type.
 * 
 * Constraint T1:
 *   The type of the inputs 'x_zero_point' and 'x'.
 *   Allowed Types: tensor_tensor(float8e4m3fn), tensor_tensor(float8e4m3fnuz),
 *                  tensor_tensor(float8e5m2), tensor_tensor(float8e5m2fnuz),
 *                  tensor_int16, tensor_int32, tensor_tensor(int4),
 *                  tensor_int8, tensor_uint16, tensor_tensor(uint4),
 *                  tensor_uint8
 * 
 * Constraint T2:
 *   'x_scale' determines the output type.
 *   Allowed Types: tensor_bfloat16, tensor_float, tensor_float16
 * Input T1 x:
 *   N-D quantized input tensor to be de-quantized.
 *   Allowed Types: tensor_tensor(float8e4m3fn), tensor_tensor(float8e4m3fnuz),
 *                  tensor_tensor(float8e5m2), tensor_tensor(float8e5m2fnuz),
 *                  tensor_int16, tensor_int32, tensor_tensor(int4),
 *                  tensor_int8, tensor_uint16, tensor_tensor(uint4),
 *                  tensor_uint8
 * 
 * Input T2 x_scale:
 *   Scale for input `x`. For per-tensor/layer dequantization the scale is a
 *   scalar, for per per-axis dequantization it is a 1-D Tensor and for blocked
 *   dequantization it has the same shape as the input, except for one
 *   dimension in which blocking is performed.
 *   Allowed Types: tensor_bfloat16, tensor_float, tensor_float16
 * 
 * Input T1 x_zero_point:
 *   Zero point for input `x`. Shape must match x_scale. It's optional. Zero
 *   point is 0 when it's not specified.
 *   Allowed Types: tensor_tensor(float8e4m3fn), tensor_tensor(float8e4m3fnuz),
 *                  tensor_tensor(float8e5m2), tensor_tensor(float8e5m2fnuz),
 *                  tensor_int16, tensor_int32, tensor_tensor(int4),
 *                  tensor_int8, tensor_uint16, tensor_tensor(uint4),
 *                  tensor_uint8
 * Output T2 y:
 *   N-D full precision output tensor. It has same shape as input `x`.
 *   Allowed Types: tensor_bfloat16, tensor_float, tensor_float16
 * Attribute INT axis (optional):
 *   (Optional) The axis of the dequantizing dimension of the input tensor.
 *   Used for per-axis and blocked quantization. Negative value means counting
 *   dimensions from the back. Accepted range is `[-r, r-1]` where `r =
 *   rank(input)`.
 * 
 * Attribute INT block_size (optional):
 *   (Optional) The size of the quantization block (number of times every
 *   scale is replicated). Used only for blocked quantization. The block size
 *   is a positive integer. Given `x` shape `(D0, ..., Di, ..., Dn)`, `y_scale`
 *   shape `(S0, ... Si, ...Sn)` and `axis=i`, the accepted range is
 *   `[ceil(Di/Si), ceil(Di/(Si-1))-1]`
 *
 * @since version 21
 *
 * @see github/workspace/onnx/defs/quantization/defs.cc:148
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#DequantizeLinear
 */

operator_status
prepare_operator__ai_onnx__dequantizelinear__21(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__dequantizelinear__21;

typedef struct {
// no attributes
} context_operator__ai_onnx__dequantizelinear__21;

operator_executer
resolve_operator__ai_onnx__dequantizelinear__21(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(float8e4m3fn)__T2_tensor_bfloat16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(float8e4m3fn)__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(float8e4m3fn)__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(float8e4m3fnuz)__T2_tensor_bfloat16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(float8e4m3fnuz)__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(float8e4m3fnuz)__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(float8e5m2)__T2_tensor_bfloat16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(float8e5m2)__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(float8e5m2)__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(float8e5m2fnuz)__T2_tensor_bfloat16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(float8e5m2fnuz)__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(float8e5m2fnuz)__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_int16__T2_tensor_bfloat16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_int16__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_int16__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_int32__T2_tensor_bfloat16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_int32__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_int32__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(int4)__T2_tensor_bfloat16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(int4)__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(int4)__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_int8__T2_tensor_bfloat16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_int8__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_int8__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_uint16__T2_tensor_bfloat16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_uint16__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_uint16__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(uint4)__T2_tensor_bfloat16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(uint4)__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_tensor(uint4)__T2_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_uint8__T2_tensor_bfloat16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_uint8__T2_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__21__T1_tensor_uint8__T2_tensor_float16(
    node_context *ctx
);

# endif