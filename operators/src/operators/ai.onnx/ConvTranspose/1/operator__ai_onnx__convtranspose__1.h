//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__CONVTRANSPOSE__1_H
# define OPERATOR_OPERATOR__AI_ONNX__CONVTRANSPOSE__1_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'ConvTranspose' version 1
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * The convolution transpose operator consumes an input tensor and a filter,
 * and computes the output.
 * 
 * If the pads parameter is provided the shape of the output is calculated via the following equation:
 * 
 *   output_shape[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - pads[start_i] - pads[end_i]
 * 
 * output_shape can also be explicitly specified in which case pads values are auto generated using these equations:
 * 
 *   total_padding[i] = stride[i] * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - output_shape[i]
 *   If (auto_pads != SAME_UPPER): pads[start_i] = total_padding[i]/2; pads[end_i] = total_padding[i] - (total_padding[i]/2)
 *   Else: pads[start_i] = total_padding[i] - (total_padding[i]/2); pads[end_i] = (total_padding[i]/2).
 * 
 * Constraint T:
 *   Constrain input and output types to float tensors.
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * Input T X:
 *   Input data tensor from previous layer; has size (N x C x H x W), where N
 *   is the batch size, C is the number of channels, and H and W are the height
 *   and width. Note that this is for the 2D image. Otherwise the size is (N x
 *   C x D1 x D2 ... x Dn)
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * 
 * Input T W:
 *   The weight tensor that will be used in the convolutions; has size (C x
 *   M/group x kH x kW), where C is the number of channels, and kH and kW are
 *   the height and width of the kernel, and M is the number of feature maps.
 *   For more than 2 dimensions, the weight shape will be (C x M/group x k1 x
 *   k2 x ... x kn), where (k1 x k2 x ... x kn) is the dimension of the kernel.
 *   The number of channels in the output should be equal to W.shape[1] * group
 *   (assuming zero based indices of the shape array)
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * 
 * Input T B:
 *   Optional 1D bias to be added to the convolution, has size of M.
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * Output T Y:
 *   Output data tensor that contains the result of the convolution. The
 *   output dimensions are functions of the kernel size, stride size, pad
 *   lengths and group count. The number of channels in the output should be
 *   equal to W.shape[1] * group (assuming zero based indices of the shape
 *   array)
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * Attribute STRING auto_pad (optional):
 *   auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where
 *   default value is NOTSET, which means explicit padding is used. SAME_UPPER
 *   or SAME_LOWER mean pad the input so that the output spatial size match the
 *   input.In case of odd number add the extra padding at the end for
 *   SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding.
 * 
 * Attribute INTS dilations (optional):
 *   dilation value along each spatial axis of the filter.
 * 
 * Attribute INT group (optional):
 *   number of groups input channels and output channels are divided into.
 * 
 * Attribute INTS kernel_shape (optional):
 *   The shape of the convolution kernel. If not present, should be inferred
 *   from input W.
 * 
 * Attribute INTS output_padding (optional):
 *   The zero-padding added to one side of the output. This is also called
 *   adjs/adjustment in some frameworks.
 * 
 * Attribute INTS output_shape (optional):
 *   The shape of the output can be explicitly set which will cause pads
 *   values to be auto generated. If output_shape is specified pads values are
 *   ignored. See doc for details for equations to generate pads
 * 
 * Attribute INTS pads (optional):
 *   Padding for the beginning and ending along each spatial axis, it can take
 *   any value greater than or equal to 0. The value represent the number of
 *   pixels added to the beginning and end part of the corresponding axis.
 *   `pads` format should be as follow [x1_begin, x2_begin...x1_end,
 *   x2_end,...], where xi_begin the number of pixels added at the beginning of
 *   axis `i` and xi_end, the number of pixels added at the end of axis `i`.
 *   This attribute cannot be used simultaneously with auto_pad attribute. If
 *   not present, the padding defaults to 0 along start and end of each spatial
 *   axis.
 * 
 * Attribute INTS strides (optional):
 *   Stride along each spatial axis.
 *
 * @since version 1
 *
 * @see github/workspace/onnx/defs/nn/old.cc:3073
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConvTranspose
 */

operator_status
prepare_operator__ai_onnx__convtranspose__1(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__convtranspose__1;

typedef struct {
// no attributes
} context_operator__ai_onnx__convtranspose__1;

operator_executer
resolve_operator__ai_onnx__convtranspose__1(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__convtranspose__1(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__convtranspose__1__T_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__convtranspose__1__T_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__convtranspose__1__T_tensor_float16(
    node_context *ctx
);

# endif