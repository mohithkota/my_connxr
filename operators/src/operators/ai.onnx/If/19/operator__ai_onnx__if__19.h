//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__IF__19_H
# define OPERATOR_OPERATOR__AI_ONNX__IF__19_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'If' version 19
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * If conditional
 * 
 * Constraint V:
 *   All Tensor, Sequence(Tensor), Optional(Tensor), and
 *   Optional(Sequence(Tensor)) types up to IRv9.
 *   Allowed Types: seq_tensor_bfloat16, seq_tensor_bool,
 *                  seq_tensor_complex128, seq_tensor_complex64,
 *                  seq_tensor_double, seq_tensor_float, seq_tensor_float16,
 *                  seq_tensor_int16, seq_tensor_int32, seq_tensor_int64,
 *                  seq_tensor_int8, seq_tensor_string, seq_tensor_uint16,
 *                  seq_tensor_uint32, seq_tensor_uint64, seq_tensor_uint8,
 *                  tensor_bfloat16, tensor_bool, tensor_complex128,
 *                  tensor_complex64, tensor_double, tensor_float,
 *                  tensor_float16, tensor_tensor(float8e4m3fn),
 *                  tensor_tensor(float8e4m3fnuz), tensor_tensor(float8e5m2),
 *                  tensor_tensor(float8e5m2fnuz), tensor_int16, tensor_int32,
 *                  tensor_int64, tensor_int8, tensor_string, tensor_uint16,
 *                  tensor_uint32, tensor_uint64, tensor_uint8,
 *                  seq_tensor_bfloat16, seq_tensor_bool, seq_tensor_complex128,
 *                  seq_tensor_complex64, seq_tensor_double, seq_tensor_float,
 *                  seq_tensor_float16, seq_tensor_tensor(float8e4m3fn),
 *                  seq_tensor_tensor(float8e4m3fnuz),
 *                  seq_tensor_tensor(float8e5m2),
 *                  seq_tensor_tensor(float8e5m2fnuz), seq_tensor_int16,
 *                  seq_tensor_int32, seq_tensor_int64, seq_tensor_int8,
 *                  seq_tensor_string, seq_tensor_uint16, seq_tensor_uint32,
 *                  seq_tensor_uint64, seq_tensor_uint8, tensor_bfloat16,
 *                  tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16,
 *                  tensor_tensor(float8e4m3fn), tensor_tensor(float8e4m3fnuz),
 *                  tensor_tensor(float8e5m2), tensor_tensor(float8e5m2fnuz),
 *                  tensor_int16, tensor_int32, tensor_int64, tensor_int8,
 *                  tensor_string, tensor_uint16, tensor_uint32, tensor_uint64,
 *                  tensor_uint8
 * 
 * Constraint B:
 *   Only bool
 *   Allowed Types: tensor_bool
 * Input B cond:
 *   Condition for the if. The tensor must contain a single element.
 *   Allowed Types: tensor_bool
 * Output V outputs:
 *   Values that are live-out to the enclosing scope. The return values in the
 *   `then_branch` and `else_branch` must be of the same data type. The
 *   `then_branch` and `else_branch` may produce tensors with the same element
 *   type and different shapes. If corresponding outputs from the then-branch
 *   and the else-branch have static shapes S1 and S2, then the shape of the
 *   corresponding output variable of the if-node (if present) must be
 *   compatible with both S1 and S2 as it represents the union of both possible
 *   shapes.For example, if in a model file, the first output of `then_branch`
 *   is typed float tensor with shape [2] and the first output of `else_branch`
 *   is another float tensor with shape [3], If's first output should have (a)
 *   no shape set, or (b) a shape of rank 1 with neither `dim_value` nor
 *   `dim_param` set, or (c) a shape of rank 1 with a unique `dim_param`. In
 *   contrast, the first output cannot have the shape [2] since [2] and [3] are
 *   not compatible.
 *   Allowed Types: seq_tensor_bfloat16, seq_tensor_bool,
 *                  seq_tensor_complex128, seq_tensor_complex64,
 *                  seq_tensor_double, seq_tensor_float, seq_tensor_float16,
 *                  seq_tensor_int16, seq_tensor_int32, seq_tensor_int64,
 *                  seq_tensor_int8, seq_tensor_string, seq_tensor_uint16,
 *                  seq_tensor_uint32, seq_tensor_uint64, seq_tensor_uint8,
 *                  tensor_bfloat16, tensor_bool, tensor_complex128,
 *                  tensor_complex64, tensor_double, tensor_float,
 *                  tensor_float16, tensor_tensor(float8e4m3fn),
 *                  tensor_tensor(float8e4m3fnuz), tensor_tensor(float8e5m2),
 *                  tensor_tensor(float8e5m2fnuz), tensor_int16, tensor_int32,
 *                  tensor_int64, tensor_int8, tensor_string, tensor_uint16,
 *                  tensor_uint32, tensor_uint64, tensor_uint8,
 *                  seq_tensor_bfloat16, seq_tensor_bool, seq_tensor_complex128,
 *                  seq_tensor_complex64, seq_tensor_double, seq_tensor_float,
 *                  seq_tensor_float16, seq_tensor_tensor(float8e4m3fn),
 *                  seq_tensor_tensor(float8e4m3fnuz),
 *                  seq_tensor_tensor(float8e5m2),
 *                  seq_tensor_tensor(float8e5m2fnuz), seq_tensor_int16,
 *                  seq_tensor_int32, seq_tensor_int64, seq_tensor_int8,
 *                  seq_tensor_string, seq_tensor_uint16, seq_tensor_uint32,
 *                  seq_tensor_uint64, seq_tensor_uint8, tensor_bfloat16,
 *                  tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16,
 *                  tensor_tensor(float8e4m3fn), tensor_tensor(float8e4m3fnuz),
 *                  tensor_tensor(float8e5m2), tensor_tensor(float8e5m2fnuz),
 *                  tensor_int16, tensor_int32, tensor_int64, tensor_int8,
 *                  tensor_string, tensor_uint16, tensor_uint32, tensor_uint64,
 *                  tensor_uint8
 * Attribute GRAPH else_branch :
 *   Graph to run if condition is false. Has N outputs: values you wish to be
 *   live-out to the enclosing scope. The number of outputs must match the
 *   number of outputs in the then_branch.
 * 
 * Attribute GRAPH then_branch :
 *   Graph to run if condition is true. Has N outputs: values you wish to be
 *   live-out to the enclosing scope. The number of outputs must match the
 *   number of outputs in the else_branch.
 *
 * @since version 19
 *
 * @see github/workspace/onnx/defs/controlflow/old.cc:32
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#If
 */

operator_status
prepare_operator__ai_onnx__if__19(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__if__19;

typedef struct {
// no attributes
} context_operator__ai_onnx__if__19;

operator_executer
resolve_operator__ai_onnx__if__19(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__if__19(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__if__19__B_tensor_bool(
    node_context *ctx
);

# endif