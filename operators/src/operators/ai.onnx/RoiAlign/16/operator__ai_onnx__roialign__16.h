//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__ROIALIGN__16_H
# define OPERATOR_OPERATOR__AI_ONNX__ROIALIGN__16_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'RoiAlign' version 16
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * Region of Interest (RoI) align operation described in the
 * [Mask R-CNN paper](https://arxiv.org/abs/1703.06870).
 * RoiAlign consumes an input tensor X and region of interests (rois)
 * to apply pooling across each RoI; it produces a 4-D tensor of shape
 * (num_rois, C, output_height, output_width).
 * 
 * RoiAlign is proposed to avoid the misalignment by removing
 * quantizations while converting from original image into feature
 * map and from feature map into RoI feature; in each ROI bin,
 * the value of the sampled locations are computed directly
 * through bilinear interpolation.
 * 
 * Constraint T1:
 *   Constrain types to float tensors.
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * 
 * Constraint T2:
 *   Constrain types to int tensors.
 *   Allowed Types: tensor_int64
 * Input T1 X:
 *   Input data tensor from the previous operator; 4-D feature map of shape
 *   (N, C, H, W), where N is the batch size, C is the number of channels, and
 *   H and W are the height and the width of the data.
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * 
 * Input T1 rois:
 *   RoIs (Regions of Interest) to pool over; rois is 2-D input of shape
 *   (num_rois, 4) given as [[x1, y1, x2, y2], ...]. The RoIs' coordinates are
 *   in the coordinate system of the input image. Each coordinate set has a 1:1
 *   correspondence with the 'batch_indices' input.
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * 
 * Input T2 batch_indices:
 *   1-D tensor of shape (num_rois,) with each element denoting the index of
 *   the corresponding image in the batch.
 *   Allowed Types: tensor_int64
 * Output T1 Y:
 *   RoI pooled output, 4-D tensor of shape (num_rois, C, output_height,
 *   output_width). The r-th batch element Y[r-1] is a pooled feature map
 *   corresponding to the r-th RoI X[r-1].
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * Attribute STRING coordinate_transformation_mode (optional):
 *   Allowed values are 'half_pixel' and 'output_half_pixel'. Use the value
 *   'half_pixel' to pixel shift the input coordinates by -0.5 (the recommended
 *   behavior). Use the value 'output_half_pixel' to omit the pixel shift for
 *   the input (use this for a backward-compatible behavior).
 * 
 * Attribute STRING mode (optional):
 *   The pooling method. Two modes are supported: 'avg' and 'max'. Default is
 *   'avg'.
 * 
 * Attribute INT output_height (optional):
 *   default 1; Pooled output Y's height.
 * 
 * Attribute INT output_width (optional):
 *   default 1; Pooled output Y's width.
 * 
 * Attribute INT sampling_ratio (optional):
 *   Number of sampling points in the interpolation grid used to compute the
 *   output value of each pooled output bin. If > 0, then exactly
 *   sampling_ratio x sampling_ratio grid points are used. If == 0, then an
 *   adaptive number of grid points are used (computed as ceil(roi_width /
 *   output_width), and likewise for height). Default is 0.
 * 
 * Attribute FLOAT spatial_scale (optional):
 *   Multiplicative spatial scale factor to translate ROI coordinates from
 *   their input spatial scale to the scale used when pooling, i.e., spatial
 *   scale of the input feature map X relative to the input image. E.g.;
 *   default is 1.0f.
 *
 * @since version 16
 *
 * @see github/workspace/onnx/defs/object_detection/old.cc:24
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#RoiAlign
 */

operator_status
prepare_operator__ai_onnx__roialign__16(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__roialign__16;

typedef struct {
// no attributes
} context_operator__ai_onnx__roialign__16;

operator_executer
resolve_operator__ai_onnx__roialign__16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__roialign__16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__roialign__16__T1_tensor_double__T2_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__roialign__16__T1_tensor_float__T2_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__roialign__16__T1_tensor_float16__T2_tensor_int64(
    node_context *ctx
);

# endif