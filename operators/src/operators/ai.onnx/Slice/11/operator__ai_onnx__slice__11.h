//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__SLICE__11_H
# define OPERATOR_OPERATOR__AI_ONNX__SLICE__11_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'Slice' version 11
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * Produces a slice of the input tensor along multiple axes. Similar to numpy:
 * https://numpy.org/doc/stable/reference/routines.indexing.html
 * Slices uses `starts`, `ends`, `axes` and `steps` inputs to specify the start and end
 * dimension and step for each axis in the list of axes, it uses this information to
 * slice the input `data` tensor. If a negative value is passed for any of the
 * start or end indices, it represents number of elements before the end of that
 * dimension. If the value passed to start or end is larger than the `n` (the
 * number of elements in this dimension), it represents `n`. For slicing to the
 * end of a dimension with unknown size, it is recommended to pass in `INT_MAX`
 * when slicing forward and 'INT_MIN' when slicing backward.
 * If a negative value is passed for step, it represents slicing backward.
 * However step value cannot be 0.
 * If `axes` are omitted, they are set to `[0, ..., ndim-1]`.
 * If `steps` are omitted, they are set to `[1, ..., 1]` of length `len(starts)`
 * Example 1:
 *   data = [
 *       [1, 2, 3, 4],
 *       [5, 6, 7, 8],
 *   ]
 *   axes = [0, 1]
 *   starts = [1, 0]
 *   ends = [2, 3]
 *   steps = [1, 2]
 *   result = [
 *       [5, 7],
 *   ]
 * Example 2:
 *   data = [
 *       [1, 2, 3, 4],
 *       [5, 6, 7, 8],
 *   ]
 *   starts = [0, 1]
 *   ends = [-1, 1000]
 *   result = [
 *       [2, 3, 4],
 *   ]
 * 
 * Constraint T:
 *   Constrain input and output types to all tensor types.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * 
 * Constraint Tind:
 *   Constrain indices to integer types
 *   Allowed Types: tensor_int32, tensor_int64
 * Input T data:
 *   Tensor of data to extract slices from.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * 
 * Input Tind starts:
 *   1-D tensor of starting indices of corresponding axis in `axes`
 *   Allowed Types: tensor_int32, tensor_int64
 * 
 * Input Tind ends:
 *   1-D tensor of ending indices (exclusive) of corresponding axis in `axes`
 *   Allowed Types: tensor_int32, tensor_int64
 * 
 * Input Tind axes:
 *   1-D tensor of axes that `starts` and `ends` apply to. Negative value
 *   means counting dimensions from the back. Accepted range is [-r, r-1] where
 *   r = rank(data).
 *   Allowed Types: tensor_int32, tensor_int64
 * 
 * Input Tind steps:
 *   1-D tensor of slice step of corresponding axis in `axes`. Negative value
 *   means slicing backward. 'steps' cannot be 0. Defaults to 1.
 *   Allowed Types: tensor_int32, tensor_int64
 * Output T output:
 *   Sliced data tensor.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8

 *
 * @since version 11
 *
 * @see github/workspace/onnx/defs/tensor/old.cc:1519
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#Slice
 */

operator_status
prepare_operator__ai_onnx__slice__11(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__slice__11;

typedef struct {
// no attributes
} context_operator__ai_onnx__slice__11;

operator_executer
resolve_operator__ai_onnx__slice__11(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_bool__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_bool__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_complex128__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_complex128__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_complex64__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_complex64__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_double__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_double__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_float__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_float__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_float16__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_float16__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_int16__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_int16__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_int32__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_int32__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_int64__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_int64__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_int8__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_int8__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_string__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_string__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_uint16__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_uint16__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_uint32__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_uint32__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_uint64__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_uint64__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_uint8__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__slice__11__T_tensor_uint8__Tind_tensor_int64(
    node_context *ctx
);

# endif