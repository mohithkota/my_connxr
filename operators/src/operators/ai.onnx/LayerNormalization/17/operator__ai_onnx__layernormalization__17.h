//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__LAYERNORMALIZATION__17_H
# define OPERATOR_OPERATOR__AI_ONNX__LAYERNORMALIZATION__17_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'LayerNormalization' version 17
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * This is layer normalization defined in ONNX as function.
 *       The overall computation can be split into two stages.
 *       The first stage is standardization, which makes the
 *       normalized elements have zero mean and unit variances.
 *       The computation required by standardization can be
 *       described by the following equations.
 *       ```
 *       Mean = ReduceMean<axes=normalized_axes>(X)
 *       D = Sub(X, Mean)
 *       DD = Mul(D, D)
 *       Var = ReduceMean<axes=normalized_axes>(DD)
 *       VarEps = Add(Var, epsilon)
 *       StdDev = Sqrt(VarEps)
 *       InvStdDev = Reciprocal(StdDev)
 *       Normalized = Mul(D, InvStdDev)
 *       ```
 *       where `normalized_axes` is `[axis, ..., rank of X - 1]`.
 *       The variables `Var` and `StdDev` stand for variance and
 *       standard deviation, respectively. The second output is
 *       `Mean` and the last one is `InvStdDev`.
 *       Depending on `stash_type` attribute, the actual computation
 *       must happen in different floating-point precision.
 *       For example, if `stash_type` is 1, this operator casts
 *       all input variables to 32-bit float, perform the computation, and
 *       finally cast `Normalized` back to the original type of `X`.
 *       The second stage then scales and shifts the outcome of the
 *       first stage using
 *       ```
 *       NormalizedScaled = Mul(Normalized, Scale)
 *       Y = Add(NormalizedScaled, B)
 *       ```
 *       The second stage doesn't depends on `stash_type`.
 *       All equations are in [this syntax](https://github.com/onnx/onnx/blob/main/docs/Syntax.md).
 *       The same variable (i.e., input, output, and attribute) uses
 *       the same name in the equations above and this operator's definition.
 *       Let `d[i]` indicate the i-th dimension of `X`.
 *       If `X`'s shape is `[d[0], ..., d[axis-1], d[axis], ..., d[rank-1]]`,
 *       the shape of `Mean` and `InvStdDev` is `[d[0], ..., d[axis-1], 1, ..., 1]`.
 *       `Y` and `X` have the same shape. This operator supports unidirectional broadcasting
 *       (tensors `Scale` and `B` should be unidirectional broadcastable to tensor `X`);
 *       for more details please check [the doc](Broadcasting.md).
 * 
 * Constraint T:
 *   Constrain input types and output Y type to float tensors.
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16
 * 
 * Constraint U:
 *   Type of Mean and InvStdDev tensors.
 *   Allowed Types: tensor_bfloat16, tensor_float
 * Input T X:
 *   Tensor to be normalized.
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16
 * 
 * Input T Scale:
 *   Scale tensor.
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16
 * 
 * Input T B:
 *   Bias tensor.
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16
 * Output T Y:
 *   Normalized tensor.
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16
 * 
 * Output U Mean:
 *   Saved mean used during training to speed up gradient computation
 *   Allowed Types: tensor_bfloat16, tensor_float
 * 
 * Output U InvStdDev:
 *   Saved inverse standard deviation used during training to speed up
 *   gradient computation.
 *   Allowed Types: tensor_bfloat16, tensor_float
 * Attribute INT axis (optional):
 *   The first normalization dimension. If rank(X) is r, axis' allowed range
 *   is [-r, r). Negative value means counting dimensions from the back.
 * 
 * Attribute FLOAT epsilon (optional):
 *   The epsilon value to use to avoid division by zero.
 * 
 * Attribute INT stash_type (optional):
 *   Type of Mean and InvStdDev. This also specifies stage one's computation
 *   precision.
 *
 * @since version 17
 *
 * @see github/workspace/onnx/defs/nn/defs.cc:2601
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#LayerNormalization
 */

operator_status
prepare_operator__ai_onnx__layernormalization__17(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__layernormalization__17;

typedef struct {
// no attributes
} context_operator__ai_onnx__layernormalization__17;

operator_executer
resolve_operator__ai_onnx__layernormalization__17(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__layernormalization__17(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__layernormalization__17__T_tensor_bfloat16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__layernormalization__17__T_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__layernormalization__17__T_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__layernormalization__17__T_tensor_float16(
    node_context *ctx
);

# endif