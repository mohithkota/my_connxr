//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__GROUPNORMALIZATION__21_H
# define OPERATOR_OPERATOR__AI_ONNX__GROUPNORMALIZATION__21_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'GroupNormalization' version 21
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * A GroupNormalization function. Carries out group normalization as described in
 * the paper https://arxiv.org/abs/1803.08494
 * 
 * This operator transforms input according to
 * ```
 * y = scale * (x - mean) / sqrt(variance + epsilon) + bias,
 * ```
 * where the mean and variance are computed per instance per group of channels, and
 * `scale` and `bias` should be specified for each group of channels. The number of
 * groups `num_groups` should be divisible by the number of channels so that there are
 * an equal number of channels per group.
 * 
 * The overall computation has two stages: the first stage normalizes the elements to
 * have zero mean and unit variance for each instance in each group, and the second
 * stage scales and shifts the results of the first stage. The floating-point precision
 * used in the first stage is determined by the `stash_type` attribute. For example,
 * if `stash_type` is 1, the operator casts all input variables to 32-bit float,
 * performs the computation, and finally casts the normalized results back to the
 * original type of `X`. The second stage does not depend on `stash_type`.
 * 
 * When the number of groups is the same as the number of channels, this operator is
 * equivalent to InstanceNormalization. When there is only one group, this operator
 * is equivalent to LayerNormalization.
 * 
 * Constraint T:
 *   Constrain input and output types to float tensors.
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16
 * Input T X:
 *   Input data tensor. Dimensions for image cases are `(N x C x H x W)`,
 *   where `N` is the batch size, `C` is the number of channels, and `H` and
 *   `W` are the height and width of the data. Statistics are computed for
 *   every group of channels over `C`, `H`, and `W`. For non-image cases, the
 *   dimensions are in the form of `(N x C x D1 x D2 ... Dn)`.
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16
 * 
 * Input T scale:
 *   Scale tensor of shape `(C)`.
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16
 * 
 * Input T bias:
 *   Bias tensor of shape `(C)`.
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16
 * Output T Y:
 *   The output tensor of the same shape as `X`.
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16
 * Attribute FLOAT epsilon (optional):
 *   The epsilon value to use to avoid division by zero.
 * 
 * Attribute INT num_groups :
 *   The number of groups of channels. It should be a divisor of the number of
 *   channels `C`.
 * 
 * Attribute INT stash_type (optional):
 *   The floating-point precision used in stage one of the computation.
 *
 * @since version 21
 *
 * @see github/workspace/onnx/defs/nn/defs.cc:2719
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#GroupNormalization
 */

operator_status
prepare_operator__ai_onnx__groupnormalization__21(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__groupnormalization__21;

typedef struct {
// no attributes
} context_operator__ai_onnx__groupnormalization__21;

operator_executer
resolve_operator__ai_onnx__groupnormalization__21(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__groupnormalization__21(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__groupnormalization__21__T_tensor_bfloat16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__groupnormalization__21__T_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__groupnormalization__21__T_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__groupnormalization__21__T_tensor_float16(
    node_context *ctx
);

# endif