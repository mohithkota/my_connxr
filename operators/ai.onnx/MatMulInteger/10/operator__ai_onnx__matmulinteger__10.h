//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__MATMULINTEGER__10_H
# define OPERATOR_OPERATOR__AI_ONNX__MATMULINTEGER__10_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'MatMulInteger' version 10
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * Matrix product that behaves like [numpy.matmul](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html).
 * The production MUST never overflow. The accumulation may overflow if and only if in 32 bits.
 * 
 * Constraint T1:
 *   Constrain input A data type to 8-bit integer tensor.
 *   Allowed Types: tensor_int8, tensor_uint8
 * 
 * Constraint T2:
 *   Constrain input B data type to 8-bit integer tensor.
 *   Allowed Types: tensor_int8, tensor_uint8
 * 
 * Constraint T3:
 *   Constrain output Y data type as 32-bit integer tensor.
 *   Allowed Types: tensor_int32
 * Input T1 A:
 *   N-dimensional matrix A
 *   Allowed Types: tensor_int8, tensor_uint8
 * 
 * Input T2 B:
 *   N-dimensional matrix B
 *   Allowed Types: tensor_int8, tensor_uint8
 * 
 * Input T1 a_zero_point:
 *   Zero point tensor for input 'A'. It's optional and default value is 0. It
 *   could be a scalar or N-D tensor. Scalar refers to per tensor quantization
 *   whereas N-D refers to per row quantization. If the input is 2D of shape
 *   [M, K] then zero point tensor may be an M element vector [zp_1, zp_2, ...,
 *   zp_M]. If the input is N-D tensor with shape [D1, D2, M, K] then zero
 *   point tensor may have shape [D1, D2, M, 1].
 *   Allowed Types: tensor_int8, tensor_uint8
 * 
 * Input T2 b_zero_point:
 *   Zero point tensor for input 'B'. It's optional and default value is 0. It
 *   could be a scalar or a N-D tensor, Scalar refers to per tensor
 *   quantization whereas N-D refers to per col quantization. If the input is
 *   2D of shape [K, N] then zero point tensor may be an N element vector
 *   [zp_1, zp_2, ..., zp_N]. If the input is N-D tensor with shape [D1, D2, K,
 *   N] then zero point tensor may have shape [D1, D2, 1, N].
 *   Allowed Types: tensor_int8, tensor_uint8
 * Output T3 Y:
 *   Matrix multiply results from A * B
 *   Allowed Types: tensor_int32

 *
 * @since version 10
 *
 * @see github/workspace/onnx/defs/math/defs.cc:1950
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#MatMulInteger
 */

operator_status
prepare_operator__ai_onnx__matmulinteger__10(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__matmulinteger__10;

typedef struct {
// no attributes
} context_operator__ai_onnx__matmulinteger__10;

operator_executer
resolve_operator__ai_onnx__matmulinteger__10(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__matmulinteger__10(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__matmulinteger__10__T1_tensor_int8__T2_tensor_int8(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__matmulinteger__10__T1_tensor_int8__T2_tensor_uint8(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__matmulinteger__10__T1_tensor_uint8__T2_tensor_int8(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__matmulinteger__10__T1_tensor_uint8__T2_tensor_uint8(
    node_context *ctx
);

# endif