//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__COMPRESS__9_H
# define OPERATOR_OPERATOR__AI_ONNX__COMPRESS__9_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'Compress' version 9
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * Selects slices from an input tensor along a given axis where condition evaluates to True for each axis index.
 *     In case axis is not provided, input is flattened before elements are selected.
 *     Compress behaves like numpy.compress: https://docs.scipy.org/doc/numpy/reference/generated/numpy.compress.html
 * 
 * Constraint T:
 *   Constrain input and output types to all tensor types.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * 
 * Constraint T1:
 *   Constrain to boolean tensors.
 *   Allowed Types: tensor_bool
 * Input T input:
 *   Tensor of rank r >= 1.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * 
 * Input T1 condition:
 *   Rank 1 tensor of booleans to indicate which slices or data elements to be
 *   selected. Its length can be less than the input length alone the axis or
 *   the flattened input size if axis is not specified. In such cases data
 *   slices or elements exceeding the condition length are discarded.
 *   Allowed Types: tensor_bool
 * Output T output:
 *   Tensor of rank r if axis is specified. Otherwise output is a Tensor of
 *   rank 1.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * Attribute INT axis (optional):
 *   (Optional) Axis along which to take slices. If not specified, input is
 *   flattened before elements being selected.
 *
 * @since version 9
 *
 * @see github/workspace/onnx/defs/tensor/old.cc:5329
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#Compress
 */

operator_status
prepare_operator__ai_onnx__compress__9(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__compress__9;

typedef struct {
// no attributes
} context_operator__ai_onnx__compress__9;

operator_executer
resolve_operator__ai_onnx__compress__9(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_bool__T1_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_complex128__T1_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_complex64__T1_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_double__T1_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_float__T1_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_float16__T1_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_int16__T1_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_int32__T1_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_int64__T1_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_int8__T1_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_string__T1_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_uint16__T1_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_uint32__T1_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_uint64__T1_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__compress__9__T_tensor_uint8__T1_tensor_bool(
    node_context *ctx
);

# endif