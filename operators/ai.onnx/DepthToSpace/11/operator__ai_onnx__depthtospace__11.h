//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__DEPTHTOSPACE__11_H
# define OPERATOR_OPERATOR__AI_ONNX__DEPTHTOSPACE__11_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'DepthToSpace' version 11
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * DepthToSpace rearranges (permutes) data from depth into blocks of spatial data.
 * This is the reverse transformation of SpaceToDepth. More specifically, this op outputs a copy of
 * the input tensor where values from the depth dimension are moved in spatial blocks to the height
 * and width dimensions. By default, `mode` = `DCR`.
 * In the DCR mode, elements along the depth dimension from the input tensor are rearranged in the
 * following order: depth, column, and then row. The output y is computed from the input x as below:
 * 
 * b, c, h, w = x.shape
 * 
 * tmp = np.reshape(x, [b, blocksize, blocksize, c // (blocksize**2), h, w])
 * 
 * tmp = np.transpose(tmp, [0, 3, 4, 1, 5, 2])
 * 
 * y = np.reshape(tmp, [b, c // (blocksize**2), h * blocksize, w * blocksize])
 * 
 * 
 * In the CRD mode, elements along the depth dimension from the input tensor are rearranged in the
 * following order: column, row, and the depth. The output y is computed from the input x as below:
 * 
 * b, c, h, w = x.shape
 * 
 * tmp = np.reshape(x, [b, c // (blocksize ** 2), blocksize, blocksize, h, w])
 * 
 * tmp = np.transpose(tmp, [0, 1, 4, 2, 5, 3])
 * 
 * y = np.reshape(tmp, [b, c // (blocksize ** 2), h * blocksize, w * blocksize])
 * 
 * Constraint T:
 *   Constrain input and output types to all tensor types.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * Input T input:
 *   Input tensor of [N,C,H,W], where N is the batch axis, C is the channel or
 *   depth, H is the height and W is the width.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * Output T output:
 *   Output tensor of [N, C/(blocksize * blocksize), H * blocksize, W *
 *   blocksize].
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * Attribute INT blocksize :
 *   Blocks of [blocksize, blocksize] are moved.
 * 
 * Attribute STRING mode (optional):
 *   DCR (default) for depth-column-row order re-arrangement. Use CRD for
 *   column-row-depth order.
 *
 * @since version 11
 *
 * @see github/workspace/onnx/defs/tensor/old.cc:3032
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#DepthToSpace
 */

operator_status
prepare_operator__ai_onnx__depthtospace__11(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__depthtospace__11;

typedef struct {
// no attributes
} context_operator__ai_onnx__depthtospace__11;

operator_executer
resolve_operator__ai_onnx__depthtospace__11(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_complex128(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_complex64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_int16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_int8(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_string(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_uint16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_uint32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_uint64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__depthtospace__11__T_tensor_uint8(
    node_context *ctx
);

# endif