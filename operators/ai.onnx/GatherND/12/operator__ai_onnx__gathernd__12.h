//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__GATHERND__12_H
# define OPERATOR_OPERATOR__AI_ONNX__GATHERND__12_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'GatherND' version 12
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * Given `data` tensor of rank `r` >= 1, `indices` tensor of rank `q` >= 1, and `batch_dims` integer `b`, this operator gathers
 * slices of `data` into an output tensor of rank `q + r - indices_shape[-1] - 1 - b`.
 * 
 * `indices` is an q-dimensional integer tensor, best thought of as a `(q-1)`-dimensional tensor of index-tuples into `data`,
 * where each element defines a slice of `data`
 * 
 * `batch_dims` (denoted as `b`) is an integer indicating the number of batch dimensions, i.e the leading `b` number of dimensions of
 * `data` tensor and `indices` are representing the batches, and the gather starts from the `b+1` dimension.
 * 
 * Some salient points about the inputs' rank and shape:
 * 
 * 1) r >= 1 and q >= 1 are to be honored. There is no dependency condition to be met between ranks `r` and `q`
 * 
 * 2) The first `b` dimensions of the shape of `indices` tensor and `data` tensor must be equal.
 * 
 * 3) b < min(q, r) is to be honored.
 * 
 * 4) The `indices_shape[-1]` should have a value between 1 (inclusive) and rank `r-b` (inclusive)
 * 
 * 5) All values in `indices` are expected to be within bounds [-s, s-1] along axis of size `s` (i.e.) `-data_shape[i] <= indices[...,i] <= data_shape[i] - 1`.
 *    It is an error if any of the index values are out of bounds.
 * 
 * The output is computed as follows:
 * 
 * The output tensor is obtained by mapping each index-tuple in the `indices` tensor to the corresponding slice of the input `data`.
 * 
 * 1) If `indices_shape[-1] > r-b` => error condition
 * 
 * 2) If `indices_shape[-1] == r-b`, since the rank of `indices` is `q`, `indices` can be thought of as `N` `(q-b-1)`-dimensional tensors
 *    containing 1-D tensors of dimension `r-b`, where `N` is an integer equals to the product of 1 and all the elements in the batch dimensions
 *    of the indices_shape. Let us think of each such `r-b` ranked tensor as `indices_slice`. Each *scalar value* corresponding to `data[0:b-1,indices_slice]`
 *    is filled into the corresponding location of the `(q-b-1)`-dimensional tensor to form the `output` tensor (Example 1 below)
 * 
 * 3) If `indices_shape[-1] < r-b`, since the rank of `indices` is `q`, `indices` can be thought of as `N` `(q-b-1)`-dimensional tensor
 *    containing 1-D tensors of dimension `< r-b`. Let us think of each such tensors as `indices_slice`. Each *tensor slice* corresponding
 *    to `data[0:b-1, indices_slice , :]` is filled into the corresponding location of the `(q-b-1)`-dimensional tensor
 *    to form the `output` tensor (Examples 2, 3, 4 and 5 below)
 * 
 * This operator is the inverse of `ScatterND`.
 * 
 * `Example 1`
 * 
 *   batch_dims = 0
 * 
 *   data    = [[0,1],[2,3]]   # data_shape = [2, 2]
 * 
 *   indices = [[0,0],[1,1]]   # indices_shape = [2, 2]
 * 
 *   output  = [0,3]           # output_shape = [2]
 * 
 * `Example 2`
 * 
 *   batch_dims = 0
 * 
 *   data    = [[0,1],[2,3]]  # data_shape = [2, 2]
 * 
 *   indices = [[1],[0]]      # indices_shape = [2, 1]
 * 
 *   output  = [[2,3],[0,1]]  # output_shape = [2, 2]
 * 
 * `Example 3`
 * 
 *   batch_dims = 0
 * 
 *   data    = [[[0,1],[2,3]],[[4,5],[6,7]]] # data_shape = [2, 2, 2]
 * 
 *   indices = [[0,1],[1,0]]                 # indices_shape = [2, 2]
 * 
 *   output  = [[2,3],[4,5]]                 # output_shape = [2, 2]
 * 
 * `Example 4`
 * 
 *   batch_dims = 0
 * 
 *   data    = [[[0,1],[2,3]],[[4,5],[6,7]]] # data_shape = [2, 2, 2]
 * 
 *   indices = [[[0,1]],[[1,0]]]             # indices_shape = [2, 1, 2]
 * 
 *   output  = [[[2,3]],[[4,5]]]             # output_shape = [2, 1, 2]
 * 
 * `Example 5`
 * 
 *   batch_dims = 1
 * 
 *   data    = [[[0,1],[2,3]],[[4,5],[6,7]]] # data_shape = [2, 2, 2]
 * 
 *   indices = [[1],[0]]             # indices_shape = [2, 1]
 * 
 *   output  = [[2,3],[4,5]]             # output_shape = [2, 2]
 * 
 * Constraint T:
 *   Constrain input and output types to any tensor type.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * Input T data:
 *   Tensor of rank r >= 1.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * 
 * Input tensor(int64) indices:
 *   Tensor of rank q >= 1. All index values are expected to be within bounds
 *   [-s, s-1] along axis of size s. It is an error if any of the index values
 *   are out of bounds.
 *   Allowed Types: tensor_int64
 * Output T output:
 *   Tensor of rank q + r - indices_shape[-1] - 1.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * Attribute INT batch_dims (optional):
 *   The number of batch dimensions. The gather of indexing starts from
 *   dimension of data[batch_dims:]
 *
 * @since version 12
 *
 * @see github/workspace/onnx/defs/tensor/old.cc:3744
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#GatherND
 */

operator_status
prepare_operator__ai_onnx__gathernd__12(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__gathernd__12;

typedef struct {
// no attributes
} context_operator__ai_onnx__gathernd__12;

operator_executer
resolve_operator__ai_onnx__gathernd__12(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_complex128(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_complex64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_int16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_int8(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_string(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_uint16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_uint32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_uint64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gathernd__12__T_tensor_uint8(
    node_context *ctx
);

# endif