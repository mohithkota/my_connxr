//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorTemplate.py
#include "operator__ai_onnx__constant__19.h"
#include "tracing.h"
#include "utils.h"

operator_status
prepare_operator__ai_onnx__constant__19(
    node_context *ctx
)
{
    TRACE_ENTRY(1);

    TRACE_NODE(2, true, ctx->onnx_node);

    /* UNCOMMENT AS NEEDED */

    

    

    // Onnx__AttributeProto *a_sparse_value = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"sparse_value");
    // Onnx__AttributeProto *a_value = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"value");
    // Onnx__AttributeProto *a_value_float = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"value_float");
    // Onnx__AttributeProto *a_value_floats = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"value_floats");
    // Onnx__AttributeProto *a_value_int = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"value_int");
    // Onnx__AttributeProto *a_value_ints = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"value_ints");
    // Onnx__AttributeProto *a_value_string = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"value_string");
    // Onnx__AttributeProto *a_value_strings = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"value_strings");

    // TRACE_ATTRIBUTE(2, a_sparse_value, a_sparse_value);
    // TRACE_ATTRIBUTE(2, a_value, a_value);
    // TRACE_ATTRIBUTE(2, a_value_float, a_value_float);
    // TRACE_ATTRIBUTE(2, a_value_floats, a_value_floats);
    // TRACE_ATTRIBUTE(2, a_value_int, a_value_int);
    // TRACE_ATTRIBUTE(2, a_value_ints, a_value_ints);
    // TRACE_ATTRIBUTE(2, a_value_string, a_value_string);
    // TRACE_ATTRIBUTE(2, a_value_strings, a_value_strings);

    // Onnx__TensorProto *o_output = searchOutputByName(ctx, 0);

    /* ALLOCATE AND INITIALIZE CONTEXT HERE IF NEEDED */

    

    // context_operator__ai_onnx__constant__19 *op_ctx = NULL;
    // op_ctx = malloc(sizeof(context_operator__ai_onnx__constant__19));
    // TRACE_FATAL(0 , !op_ctx, "could not allocate executer_context");

    

    TRACE_VAR(2, true, op_ctx->sparse_value, "%p");
    TRACE_TENSOR(2, true, op_ctx->value);
    TRACE_VAR(2, true, op_ctx->value_float, "%f");
    TRACE_ARRAY(2, true, op_ctx->value_floats, , op_ctx->n_value_floats, "%f");
    TRACE_VAR(2, true, op_ctx->value_int, "%" PRId64);
    TRACE_ARRAY(2, true, op_ctx->value_ints, , op_ctx->n_value_ints, "%" PRId64);
    TRACE_VAR(2, true, op_ctx->value_string, "\"%s\"");
    TRACE_ARRAY(2, true, op_ctx->value_strings, , op_ctx->n_value_strings, "\"%s\"");

    /* INITIALIZE OUTPUTS DATA_TYPE AND SHAPE HERE */


    /* MALLOC OUTPUT TENSORS HERE */

    // mallocTensorData(o_output);

    // TRACE_TENSOR(2, true, o_output);

    /* CHOOSE EXECUTER AND CONTEXT HERE */
    /* YOU MAY USE THE GENERATED RESOLVER */

    // ctx->executer = resolve_operator__ai_onnx__constant__19(ctx);
    // ctx->executer_context = op_ctx;

    TRACE_EXIT(1);

    /* CHANGE RETURN CODE IF THIS PREPARER IS VALID */
    return OP_ENOSYS;
    // return OP_OK;
}