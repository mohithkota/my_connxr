//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__DEQUANTIZELINEAR__10_H
# define OPERATOR_OPERATOR__AI_ONNX__DEQUANTIZELINEAR__10_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'DequantizeLinear' version 10
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * The linear dequantization operator. It consumes a quantized tensor, a scale, a zero point to compute the full precision tensor.
 * The dequantization formula is y = (x - x_zero_point) * x_scale. 'x_scale' and 'x_zero_point' are both scalars.
 * 'x_zero_point' and 'x' must have same type. 'x' and 'y' must have same shape. In the case of dequantizing int32,
 * there's no zero point (zero point is supposed to be 0).
 * 
 * Constraint T:
 *   Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.
 *   Allowed Types: tensor_int32, tensor_int8, tensor_uint8
 * Input T x:
 *   N-D quantized input tensor to be de-quantized.
 *   Allowed Types: tensor_int32, tensor_int8, tensor_uint8
 * 
 * Input tensor(float) x_scale:
 *   Scale for input 'x'. It's a scalar, which means a per-tensor/layer
 *   quantization.
 *   Allowed Types: tensor_float
 * 
 * Input T x_zero_point:
 *   Zero point for input 'x'. It's a scalar, which means a per-tensor/layer
 *   quantization. It's optional. 0 is the default value when it's not
 *   specified.
 *   Allowed Types: tensor_int32, tensor_int8, tensor_uint8
 * Output tensor(float) y:
 *   N-D full precision output tensor. It has same shape as input 'x'.
 *   Allowed Types: tensor_float

 *
 * @since version 10
 *
 * @see github/workspace/onnx/defs/quantization/old.cc:294
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#DequantizeLinear
 */

operator_status
prepare_operator__ai_onnx__dequantizelinear__10(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__dequantizelinear__10;

typedef struct {
// no attributes
} context_operator__ai_onnx__dequantizelinear__10;

operator_executer
resolve_operator__ai_onnx__dequantizelinear__10(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__10(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__10__T_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__10__T_tensor_int8(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__dequantizelinear__10__T_tensor_uint8(
    node_context *ctx
);

# endif