//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__ISINF__20_H
# define OPERATOR_OPERATOR__AI_ONNX__ISINF__20_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'IsInf' version 20
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * Map infinity to true and other values to false.
 * 
 * Constraint T1:
 *   Constrain input types to float tensors.
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16, tensor_tensor(float8e4m3fn),
 *                  tensor_tensor(float8e4m3fnuz), tensor_tensor(float8e5m2),
 *                  tensor_tensor(float8e5m2fnuz)
 * 
 * Constraint T2:
 *   Constrain output types to boolean tensors.
 *   Allowed Types: tensor_bool
 * Input T1 X:
 *   input
 *   Allowed Types: tensor_bfloat16, tensor_double, tensor_float,
 *                  tensor_float16, tensor_tensor(float8e4m3fn),
 *                  tensor_tensor(float8e4m3fnuz), tensor_tensor(float8e5m2),
 *                  tensor_tensor(float8e5m2fnuz)
 * Output T2 Y:
 *   output
 *   Allowed Types: tensor_bool
 * Attribute INT detect_negative (optional):
 *   (Optional) Whether map negative infinity to true. Default to 1 so that
 *   negative infinity induces true. Set this attribute to 0 if negative
 *   infinity should be mapped to false.
 * 
 * Attribute INT detect_positive (optional):
 *   (Optional) Whether map positive infinity to true. Default to 1 so that
 *   positive infinity induces true. Set this attribute to 0 if positive
 *   infinity should be mapped to false.
 *
 * @since version 20
 *
 * @see github/workspace/onnx/defs/tensor/defs.cc:2973
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#IsInf
 */

operator_status
prepare_operator__ai_onnx__isinf__20(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__isinf__20;

typedef struct {
// no attributes
} context_operator__ai_onnx__isinf__20;

operator_executer
resolve_operator__ai_onnx__isinf__20(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__isinf__20(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__isinf__20__T1_tensor_bfloat16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__isinf__20__T1_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__isinf__20__T1_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__isinf__20__T1_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__isinf__20__T1_tensor_tensor(float8e4m3fn)(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__isinf__20__T1_tensor_tensor(float8e4m3fnuz)(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__isinf__20__T1_tensor_tensor(float8e5m2)(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__isinf__20__T1_tensor_tensor(float8e5m2fnuz)(
    node_context *ctx
);

# endif