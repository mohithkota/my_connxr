//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorTypeResolver.py
#include "operator__ai_onnx__batchnormalization__14.h"
#include "operators/operator_stub.h"
#include <inttypes.h>
#include <stdio.h>

operator_executer
resolve_operator__ai_onnx__batchnormalization__14(
    node_context *ctx
){
    operator_executer executer = NULL;
    {
    uint32_t T = 0;
if (ctx->inputs[0]) {
    T = ctx->inputs[0]->data_type;
}
uint32_t U = 0;
if (ctx->inputs[3]) {
    U = ctx->inputs[3]->data_type;
}
    switch ( T ) {
    case 0: //constrained tensor is not set (maybe optional?), just take next case
    case ONNX__TENSOR_PROTO__DATA_TYPE__BFLOAT16: { switch ( U ) {
    case 0: //constrained tensor is not set (maybe optional?), just take next case
    case ONNX__TENSOR_PROTO__DATA_TYPE__BFLOAT16: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_bfloat16__U_tensor_bfloat16; break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__DOUBLE: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_bfloat16__U_tensor_double; break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__FLOAT: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_bfloat16__U_tensor_float; break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__FLOAT16: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_bfloat16__U_tensor_float16; break; }
    default: {
        fprintf(stderr, "no matching type for operator__ai_onnx__batchnormalization__14 and constraint 'U' with type '%s' found!\n",operator_info_tensorType2str(U));
        break;
    }
} break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__DOUBLE: { switch ( U ) {
    case 0: //constrained tensor is not set (maybe optional?), just take next case
    case ONNX__TENSOR_PROTO__DATA_TYPE__BFLOAT16: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_double__U_tensor_bfloat16; break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__DOUBLE: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_double__U_tensor_double; break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__FLOAT: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_double__U_tensor_float; break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__FLOAT16: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_double__U_tensor_float16; break; }
    default: {
        fprintf(stderr, "no matching type for operator__ai_onnx__batchnormalization__14 and constraint 'U' with type '%s' found!\n",operator_info_tensorType2str(U));
        break;
    }
} break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__FLOAT: { switch ( U ) {
    case 0: //constrained tensor is not set (maybe optional?), just take next case
    case ONNX__TENSOR_PROTO__DATA_TYPE__BFLOAT16: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_float__U_tensor_bfloat16; break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__DOUBLE: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_float__U_tensor_double; break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__FLOAT: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_float__U_tensor_float; break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__FLOAT16: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_float__U_tensor_float16; break; }
    default: {
        fprintf(stderr, "no matching type for operator__ai_onnx__batchnormalization__14 and constraint 'U' with type '%s' found!\n",operator_info_tensorType2str(U));
        break;
    }
} break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__FLOAT16: { switch ( U ) {
    case 0: //constrained tensor is not set (maybe optional?), just take next case
    case ONNX__TENSOR_PROTO__DATA_TYPE__BFLOAT16: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_float16__U_tensor_bfloat16; break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__DOUBLE: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_float16__U_tensor_double; break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__FLOAT: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_float16__U_tensor_float; break; }
case ONNX__TENSOR_PROTO__DATA_TYPE__FLOAT16: { executer = (operator_executer) &execute_operator__ai_onnx__batchnormalization__14__T_tensor_float16__U_tensor_float16; break; }
    default: {
        fprintf(stderr, "no matching type for operator__ai_onnx__batchnormalization__14 and constraint 'U' with type '%s' found!\n",operator_info_tensorType2str(U));
        break;
    }
} break; }
    default: {
        fprintf(stderr, "no matching type for operator__ai_onnx__batchnormalization__14 and constraint 'T' with type '%s' found!\n",operator_info_tensorType2str(T));
        break;
    }
}
}
    if (!executer) {
        executer = &operator_stub;
    }
    return executer;
}