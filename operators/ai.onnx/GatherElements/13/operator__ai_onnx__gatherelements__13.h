//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__GATHERELEMENTS__13_H
# define OPERATOR_OPERATOR__AI_ONNX__GATHERELEMENTS__13_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'GatherElements' version 13
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * GatherElements takes two inputs `data` and `indices` of the same rank r >= 1
 * and an optional attribute `axis` that identifies an axis of `data`
 * (by default, the outer-most axis, that is axis 0). It is an indexing operation
 * that produces its output by indexing into the input data tensor at index
 * positions determined by elements of the `indices` tensor.
 * Its output shape is the same as the shape of `indices` and consists of one value
 * (gathered from the `data`) for each element in `indices`.
 * 
 * For instance, in the 3-D case (r = 3), the output produced is determined
 * by the following equations:
 * ```
 * out[i][j][k] = input[index[i][j][k]][j][k] if axis = 0,
 * out[i][j][k] = input[i][index[i][j][k]][k] if axis = 1,
 * out[i][j][k] = input[i][j][index[i][j][k]] if axis = 2,
 * ```
 * 
 * This operator is also the inverse of ScatterElements. It is similar to Torch's gather operation.
 * 
 * Example 1:
 * ```
 * data = [
 *     [1, 2],
 *     [3, 4],
 * ]
 * indices = [
 *     [0, 0],
 *     [1, 0],
 * ]
 * axis = 1
 * output = [
 *     [1, 1],
 *     [4, 3],
 * ]
 * ```
 * Example 2:
 * ```
 * data = [
 *     [1, 2, 3],
 *     [4, 5, 6],
 *     [7, 8, 9],
 * ]
 * indices = [
 *     [1, 2, 0],
 *     [2, 0, 0],
 * ]
 * axis = 0
 * output = [
 *     [4, 8, 3],
 *     [7, 2, 3],
 * ]
 * ```
 * 
 * Constraint T:
 *   Constrain input and output types to any tensor type.
 *   Allowed Types: tensor_bfloat16, tensor_bool, tensor_complex128,
 *                  tensor_complex64, tensor_double, tensor_float,
 *                  tensor_float16, tensor_int16, tensor_int32, tensor_int64,
 *                  tensor_int8, tensor_string, tensor_uint16, tensor_uint32,
 *                  tensor_uint64, tensor_uint8
 * 
 * Constraint Tind:
 *   Constrain indices to integer types
 *   Allowed Types: tensor_int32, tensor_int64
 * Input T data:
 *   Tensor of rank r >= 1.
 *   Allowed Types: tensor_bfloat16, tensor_bool, tensor_complex128,
 *                  tensor_complex64, tensor_double, tensor_float,
 *                  tensor_float16, tensor_int16, tensor_int32, tensor_int64,
 *                  tensor_int8, tensor_string, tensor_uint16, tensor_uint32,
 *                  tensor_uint64, tensor_uint8
 * 
 * Input Tind indices:
 *   Tensor of int32/int64 indices, with the same rank r as the input. All
 *   index values are expected to be within bounds [-s, s-1] along axis of size
 *   s. It is an error if any of the index values are out of bounds.
 *   Allowed Types: tensor_int32, tensor_int64
 * Output T output:
 *   Tensor of the same shape as indices.
 *   Allowed Types: tensor_bfloat16, tensor_bool, tensor_complex128,
 *                  tensor_complex64, tensor_double, tensor_float,
 *                  tensor_float16, tensor_int16, tensor_int32, tensor_int64,
 *                  tensor_int8, tensor_string, tensor_uint16, tensor_uint32,
 *                  tensor_uint64, tensor_uint8
 * Attribute INT axis (optional):
 *   Which axis to gather on. Negative value means counting dimensions from
 *   the back. Accepted range is [-r, r-1] where r = rank(data).
 *
 * @since version 13
 *
 * @see github/workspace/onnx/defs/tensor/defs.cc:1655
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#GatherElements
 */

operator_status
prepare_operator__ai_onnx__gatherelements__13(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__gatherelements__13;

typedef struct {
// no attributes
} context_operator__ai_onnx__gatherelements__13;

operator_executer
resolve_operator__ai_onnx__gatherelements__13(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_bfloat16__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_bfloat16__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_bool__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_bool__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_complex128__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_complex128__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_complex64__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_complex64__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_double__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_double__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_float__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_float__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_float16__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_float16__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_int16__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_int16__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_int32__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_int32__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_int64__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_int64__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_int8__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_int8__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_string__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_string__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_uint16__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_uint16__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_uint32__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_uint32__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_uint64__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_uint64__Tind_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_uint8__Tind_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__gatherelements__13__T_tensor_uint8__Tind_tensor_int64(
    node_context *ctx
);

# endif