//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__TOPK__11_H
# define OPERATOR_OPERATOR__AI_ONNX__TOPK__11_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'TopK' version 11
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * Retrieve the top-K largest or smallest elements along a specified axis. Given an input tensor of
 * shape [a_0, a_1, ..., a_{n-1}] and integer argument k, return two outputs:
 * 
 * * Value tensor of shape [a_0, a_1, ..., a_{axis-1}, k, a_{axis+1}, ... a_{n-1}]
 *   which contains the values of the top k elements along the specified axis
 * * Index tensor of shape [a_0, a_1, ..., a_{axis-1}, k, a_{axis+1}, ... a_{n-1}] which
 *   contains the indices of the top k elements (original indices from the input
 *   tensor).
 * 
 * * If "largest" is 1 (the default value) then the k largest elements are returned.
 * * If "sorted" is 1 (the default value) then the resulting k elements will be sorted.
 * * If "sorted" is 0, order of returned 'Values' and 'Indices' are undefined.
 * 
 * Given two equivalent values, this operator uses the indices along the axis as
 * a tiebreaker. That is, the element with the lower index will appear first.
 * 
 * Constraint T:
 *   Constrain input and output types to numeric tensors.
 *   Allowed Types: tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_uint16,
 *                  tensor_uint32, tensor_uint64, tensor_uint8
 * 
 * Constraint I:
 *   Constrain index tensor to int64
 *   Allowed Types: tensor_int64
 * Input T X:
 *   Tensor of shape [a_0, a_1, ..., a_{n-1}]
 *   Allowed Types: tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_uint16,
 *                  tensor_uint32, tensor_uint64, tensor_uint8
 * 
 * Input tensor(int64) K:
 *   A 1-D tensor containing a single positive value corresponding to the
 *   number of top elements to retrieve
 *   Allowed Types: tensor_int64
 * Output T Values:
 *   Tensor of shape [a_0, a_1, ..., a_{axis-1}, k, a_{axis+1}, ... a_{n-1}]
 *   containing top K values from the input tensor
 *   Allowed Types: tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_uint16,
 *                  tensor_uint32, tensor_uint64, tensor_uint8
 * 
 * Output I Indices:
 *   Tensor of shape [a_0, a_1, ..., a_{axis-1}, k, a_{axis+1}, ... a_{n-1}]
 *   containing the corresponding input tensor indices for the top K values.
 *   Allowed Types: tensor_int64
 * Attribute INT axis (optional):
 *   Dimension on which to do the sort. Negative value means counting
 *   dimensions from the back. Accepted range is [-r, r-1] where r =
 *   rank(input).
 * 
 * Attribute INT largest (optional):
 *   Whether to return the top-K largest or smallest elements.
 * 
 * Attribute INT sorted (optional):
 *   Whether to return the elements in sorted order.
 *
 * @since version 11
 *
 * @see github/workspace/onnx/defs/math/defs.cc:1393
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#TopK
 */

operator_status
prepare_operator__ai_onnx__topk__11(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__topk__11;

typedef struct {
// no attributes
} context_operator__ai_onnx__topk__11;

operator_executer
resolve_operator__ai_onnx__topk__11(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__topk__11(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__topk__11__T_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__topk__11__T_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__topk__11__T_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__topk__11__T_tensor_int16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__topk__11__T_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__topk__11__T_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__topk__11__T_tensor_int8(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__topk__11__T_tensor_uint16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__topk__11__T_tensor_uint32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__topk__11__T_tensor_uint64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__topk__11__T_tensor_uint8(
    node_context *ctx
);

# endif