//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__MUL__1_H
# define OPERATOR_OPERATOR__AI_ONNX__MUL__1_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'Mul' version 1
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * Performs element-wise binary multiplication (with limited broadcast support).
 * 
 * If necessary the right-hand-side argument will be broadcasted to match the
 * shape of left-hand-side argument. When broadcasting is specified, the second
 * tensor can either be of element size 1 (including a scalar tensor and any
 * tensor with rank equal to or smaller than the first tensor), or having its
 * shape as a contiguous subset of the first tensor's shape. The starting of the
 * mutually equal shape is specified by the argument "axis", and if it is not set,
 * suffix matching is assumed. 1-dim expansion doesn't work yet.
 * 
 * For example, the following tensor shapes are supported (with broadcast=1):
 * 
 *   shape(A) = (2, 3, 4, 5), shape(B) = (,), i.e. B is a scalar tensor
 *   shape(A) = (2, 3, 4, 5), shape(B) = (1, 1), i.e. B is an 1-element tensor
 *   shape(A) = (2, 3, 4, 5), shape(B) = (5,)
 *   shape(A) = (2, 3, 4, 5), shape(B) = (4, 5)
 *   shape(A) = (2, 3, 4, 5), shape(B) = (3, 4), with axis=1
 *   shape(A) = (2, 3, 4, 5), shape(B) = (2), with axis=0
 * 
 * Attribute `broadcast=1` needs to be passed to enable broadcasting.
 * 
 * Constraint T:
 *   Constrain input and output types to float tensors.
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * Input T A:
 *   First operand, should share the type with the second operand.
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * 
 * Input T B:
 *   Second operand. With broadcasting can be of smaller size than A. If
 *   broadcasting is disabled it should be of the same size.
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * Output T C:
 *   Result, has same dimensions and type as A
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * Attribute INT axis (optional):
 *   If set, defines the broadcast dimensions. See doc for details.
 * 
 * Attribute INT broadcast (optional):
 *   Pass 1 to enable broadcasting
 * 
 * Attribute INTS consumed_inputs (optional):
 *   legacy optimization attribute.
 *
 * @since version 1
 *
 * @see github/workspace/onnx/defs/math/old.cc:2631
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mul
 */

operator_status
prepare_operator__ai_onnx__mul__1(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__mul__1;

typedef struct {
// no attributes
} context_operator__ai_onnx__mul__1;

operator_executer
resolve_operator__ai_onnx__mul__1(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__mul__1(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__mul__1__T_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__mul__1__T_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__mul__1__T_tensor_float16(
    node_context *ctx
);

# endif