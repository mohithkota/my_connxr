//this file was generated by ../../../../../../../../connx/connx_ajit/scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__SCATTERND__11_H
# define OPERATOR_OPERATOR__AI_ONNX__SCATTERND__11_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'ScatterND' version 11
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * ScatterND takes three inputs `data` tensor of rank r >= 1, `indices` tensor of rank q >= 1,
 * and `updates` tensor of rank q + r - indices.shape[-1] - 1. The output of the operation
 * is produced by creating a copy of the input `data`, and then updating its value to values
 * specified by `updates` at specific index positions specified by `indices`. Its output shape
 * is the same as the shape of `data`. Note that `indices` should not have duplicate entries.
 * That is, two or more `updates` for the same index-location is not supported.
 * 
 * `indices` is an integer tensor. Let k denote indices.shape[-1], the last dimension in the shape of `indices`.
 *  `indices` is treated as a (q-1)-dimensional tensor of k-tuples, where each k-tuple is a partial-index into `data`.
 * Hence, k can be a value at most the rank of `data`. When k equals rank(data), each update entry specifies an
 * update to a single element of the tensor. When k is less than rank(data) each update entry specifies an
 * update to a slice of the tensor. Index values are allowed to be negative, as per the usual
 * convention for counting backwards from the end, but are expected in the valid range.
 * 
 * `updates` is treated as a (q-1)-dimensional tensor of replacement-slice-values. Thus, the
 * first (q-1) dimensions of updates.shape must match the first (q-1) dimensions of indices.shape.
 * The remaining dimensions of `updates` correspond to the dimensions of the
 * replacement-slice-values. Each replacement-slice-value is a (r-k) dimensional tensor,
 * corresponding to the trailing (r-k) dimensions of `data`.  Thus, the shape of `updates`
 * must equal indices.shape[0:q-1] ++ data.shape[k:r-1], where ++ denotes the concatenation
 * of shapes.
 * 
 * The `output` is calculated via the following equation:
 * 
 *     output = np.copy(data)
 *     update_indices = indices.shape[:-1]
 *     for idx in np.ndindex(update_indices):
 *         output[indices[idx]] = updates[idx]
 * 
 * The order of iteration in the above loop is not specified.
 * In particular, indices should not have duplicate entries: that is, if idx1 != idx2, then indices[idx1] != indices[idx2].
 * This ensures that the output value does not depend on the iteration order.
 * 
 * This operator is the inverse of GatherND.
 * 
 * Example 1:
 * ```
 *   data    = [1, 2, 3, 4, 5, 6, 7, 8]
 *   indices = [[4], [3], [1], [7]]
 *   updates = [9, 10, 11, 12]
 *   output  = [1, 11, 3, 10, 9, 6, 7, 12]
 * ```
 * 
 * Example 2:
 * ```
 *   data    = [[[1, 2, 3, 4], [5, 6, 7, 8], [8, 7, 6, 5], [4, 3, 2, 1]],
 *              [[1, 2, 3, 4], [5, 6, 7, 8], [8, 7, 6, 5], [4, 3, 2, 1]],
 *              [[8, 7, 6, 5], [4, 3, 2, 1], [1, 2, 3, 4], [5, 6, 7, 8]],
 *              [[8, 7, 6, 5], [4, 3, 2, 1], [1, 2, 3, 4], [5, 6, 7, 8]]]
 *   indices = [[0], [2]]
 *   updates = [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],
 *              [[1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3], [4, 4, 4, 4]]]
 *   output  = [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],
 *              [[1, 2, 3, 4], [5, 6, 7, 8], [8, 7, 6, 5], [4, 3, 2, 1]],
 *              [[1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3], [4, 4, 4, 4]],
 *              [[8, 7, 6, 5], [4, 3, 2, 1], [1, 2, 3, 4], [5, 6, 7, 8]]]
 * ```
 * 
 * Constraint T:
 *   Constrain input and output types to any tensor type.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * Input T data:
 *   Tensor of rank r >= 1.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * 
 * Input tensor(int64) indices:
 *   Tensor of rank q >= 1.
 *   Allowed Types: tensor_int64
 * 
 * Input T updates:
 *   Tensor of rank q + r - indices_shape[-1] - 1.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * Output T output:
 *   Tensor of rank r >= 1.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8

 *
 * @since version 11
 *
 * @see github/workspace/onnx/defs/tensor/old.cc:2106
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#ScatterND
 */

operator_status
prepare_operator__ai_onnx__scatternd__11(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx__scatternd__11;

typedef struct {
// no attributes
} context_operator__ai_onnx__scatternd__11;

operator_executer
resolve_operator__ai_onnx__scatternd__11(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_complex128(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_complex64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_int16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_int8(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_string(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_uint16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_uint32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_uint64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx__scatternd__11__T_tensor_uint8(
    node_context *ctx
);

# endif